% ==========================================
% Bijlage
% ==========================================

\chapter{Bijlage}
\label{bijlage}

\section{Prompts}
\label{bijlage:prompts}

\subsection{Function Prompt 1}
\label{bijlage:prompt1}
Instructies voor het genereren van een docstring voor een functie versie 1.
\begin{minted}{python}
    '''For this Python function:
    ```python	
    def is_prime(n):
    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
    ```
    Leave out any imports, just return the function with the docstring and type hints.
    The function, with docstring using the google docstring style and with type hints is:
    ```python	
    def is_prime(n: int) -> bool:
    """
    Check if a number is prime.
    Args:
        n (int): The number to check.
    Returns:
        bool: True if the number is prime, False otherwise.
    """
    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
    ```
    
    For this Python function:
    ```python	
    {code}
    '''
\end{minted}

\subsection{Function Prompt 2}
\label{bijlage:prompt2}
Instructies voor het genereren van een docstring voor een functie versie 2.
\begin{minted}{python}
'''
    The following Python function is a code snippit from a Python file. 
    The following function lacs a docstring and type hints.
    Your task is to add a docstring and type hints to the function.
    You can't change the function's code, add any imports, or assume anything about the function's behavior or datatypes that is not clear from the code snippet itself.
    Below is a function that needs a docstring and type hints:
    ```python	
    def is_prime(n):
    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
    ```
    The correct outcome should be the following Python code:
    ```python	
    def is_prime(n: int) -> bool:
    """
    Check if a number is prime.
    Args:
        n (int): The number to check.
    Returns:
        bool: True if the number is prime, False otherwise.
    """
    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
    ```
    
    Now it's your turn to add a docstring and type hints to the following function:
    ```python	
    {code}
    ```
    '''
\end{minted}


\subsection{Function Prompt 3}
\label{bijlage:prompt3}
Prompt versie 3 voor het genereren van een docstring voor een functie. 
\begin{minted}{python}
    '''You are an AI documentation assistant, and your task is to generate docstrings and typehints based on the given code of a function, the function is a code snippet from a Python file.
    Do your task with the least amount of assumptions, you can't add any imports, change the code, or assume anything about the function's behavior or datatypes that is not clear from the code snippet itself.
    The purpose of the documentation is to help developers and beginners understand the function and specific usage of the code.

    An example of your task is as follows:
    The given code is:

    ```python	
    def is_prime(n):
    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
    ```

    The expected output of your task for the given code is:

    ```python	
    def is_prime(n: int) -> bool:
    """
    Check if a number is prime.

    Args:
        n (int): The number to check.

    Returns:
        bool: True if the number is prime, False otherwise.
    """

    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
    ```

    Now it's your turn to generate the docstrings and typehints for the following function of a file with these imports:
    {imports}

    The content of the code is as follows:
    {code_content}
    '''
\end{minted}

\subsection{Class Prompt 1}
\label{bijlage:prompt4}
Prompt voor het genereren van een docstring voor een klasse.
\begin{minted}{python}
    '''
    You are an AI documentation assistant, and your task is to generate docstrings and typehints based on the given code of a class, the class is a code snippet from a Python file.
    Do your task with the least amount of assumptions, you can't add any imports, change the code, or assume anything about the classes behavior or datatypes that is not clear from the code snippet itself.
    The purpose of the documentation is to help developers and beginners understand the function and specific usage of the code.

    An example of your task is as follows:
    The given code is:

    ```python
    class Circle:
        def __init__(self, radius: float) -> None:
            """
            Initialize the Circle object with a given radius.

            Args:
                radius (float): The radius of the circle.
            """
            self.radius = radius

        def calculate_area(self) -> float:
            """
            Calculate the area of the circle.

            Returns:
                float: The area of the circle.
            """
            return round(math.pi * self.radius ** 2, 2)

        def calculate_circumference(self) -> float:
            """
            Calculate the circumference of the circle.

            Returns:
                float: The circumference of the circle.
            """
            return round(2 * math.pi * self.radius, 2)
    ```

    The expected output of your task for the given code is:

    ```python
    class Circle:
        """
        A class representing a circle with methods to calculate its area and circumference.

        Attributes:
            radius (float): The radius of the circle.

        Methods:
            __init__: Initialize the Circle object with a given radius.
            calculate_area: Calculate the area of the circle.
            calculate_circumference: Calculate the circumference of the circle.
        """
    ```

    Now it's your turn to generate the docstrings and typehints for the following class of a file with these imports:
    {imports}

    The content of the code is as follows:
    {code_content}

    Only generate the class docstring

    '''
\end{minted}

\subsection{Samenvatting van een bestand}
\label{bijlage:bestand-samenvatting}
Prompt voor het genereren van een samenvatting van een bestand.
\begin{minted}{python}
    '''
    You are an AI documentation assistant, and your task is to generate a summary of the given Python file. 
    The summary should include the following information:
    - What the file does.
    - What classes are defined in the file.
    - What functions are defined in the file.
    - And a brief description of each class and function.
    - Include the file name at the beginning of the summary.
    
    You are going to generate the summary based on given function names, class names and their docstrings.
    
    Now it's your turn to generate the summary given the following code of the file: {filename}:

    {code_content}
    '''
    \end{minted}

\subsection{Bestand zonder functies of klasses}
\label{bijlage:bestand-zonder-functies}
Prompt voor het genereren van een samenvatting van een bestand zonder functies of klasses.
\begin{minted}{python}
    '''
    You are an AI documentation assistant, and your task is to generate a summary of the given Python file based on the code content.
    The summary should include the following information:
    - What the file does.
    - What is the purpose of the file.
    - What is the main functionality of the file.
    - What the output is
    - What it does when executed.
    - Include the file name at the beginning of the summary.

    An example of the output of your task is as follows:
    Given the following code content:

    ```python
    from model import get_model
    from train import train_top_layer, train_all_layers
    if __name__ == '__main__':
        model = get_model()
        train_top_layer(model)
    ```

    The expected output of your task for the given code is the summary of the file:
    
    ```python
    """
    Summary of file: main.py
    
    This file contains the main functionality for a Python application.
    It imports the get_model function from the model module and the train_top_layer and train_all_layers functions from the train module.
    When executed, it gets a model using the get_model function and trains the top layer of the model using the train_top_layer function.
    """
    ```

    You are going to generate the summary based on the given code content of the file with filename: {filename}.
    {code_content}
    '''
\end{minted}

\subsection{Project samenvatting}
\label{bijlage:prompt6}
Prompt voor het genereren van een samenvatting van een project.
\begin{minted}{python}
    '''
    You are an AI documentation assistant, and your task is to generate a summary of the given Python project.
    The summary should include the following information:
    - What the project does.
    - What files are included in the project. And what each file does. What functions and classes are defined in each file.
    - A brief description of each class and function.
    - Include the project name at the beginning of the summary.

    You are going to generate the summary based on summaries of each file in the project.
    
    Now it's your turn to generate the summary given the following project structure:
    {project_name}

    With the following folder structure:
    {folder_structure}

    And the following summaries of each file:
    {summaries}
    '''
\end{minted}

\subsection{Project samenvatting per file}
\label{bijlage:prompt7}
Prompt voor het genereren van een samenvatting van een project per bestand.
\begin{minted}{python}
'''
    You are an AI documentation assistant, and your task is to generate a markdown summary of a file.
    For the following file summary:
    """
    Summary of file: crop_images.py

    This file contains the implementation of functions for cropping and padding images.

    Functions:
        crop_faces: Crop faces from an image using a specified bounding box.
        crop_image: Crop a specified region from an image.
        pad_img_to_fit_bbox: Pad an image to fit a specified bounding box.
    """

    The output should be:
    - **crop_images.py**: 
        - Contains functions for cropping and padding images:
          - `crop_faces`: Crop faces from an image using the given bounding boxes.
          - `crop_image`: Crop a specific region from an image based on the provided coordinates.
          - `pad_img_to_fit_bbox`: Pad an image to fit the specified bounding box.

    You are going to generate the markdown summary for the file: {file} with the following summary:
    {summary}
    '''
\end{minted}


\section{Code}
\label{bijlage:code}

\subsection{Vervangen van de code van een functie door de gegenereerde docstring. v1}
\label{bijlage:vervangen-v1}
\begin{minted}{python}
def replace_functions(self, functions):
    tree = self.tree
    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)) and node.name in functions:
            new_func_def = ast.parse(functions[node.name]).body
            tree.body.insert(tree.body.index(node), new_func_def)        
    self.tree = tree
\end{minted}

\subsection{Vervangen van de code van een functie door de gegenereerde docstring. v2}
\label{bijlage:vervangen-v2}
Versie 2 van de functie om de code van een functie te vervangen door de gegenereerde docstring.
\begin{minted}{python}
def replace_functions(self, functions):
    tree = self.tree
    for node in ast.walk(tree):
        if isinstance(node, ast.ClassDef):
            for child_node in node.body:
                if isinstance(child_node, (ast.FunctionDef, ast.AsyncFunctionDef)) and child_node.name in functions:
                    new_func_def = ast.parse(functions[child_node.name]).body[0]
                    new_func_def.body.extend(child_node.body)
                    idx = node.body.index(child_node)
                    node.body.insert(idx, new_func_def)
                    node.body.remove(child_node)
                    functions.pop(child_node.name)
        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)) and node.name in functions:
            new_func_def = ast.parse(functions[node.name]).body[0]
            new_func_def.body.extend(node.body)
            tree.body.insert(tree.body.index(node), new_func_def)
            tree.body.remove(node)
            functions.pop(node.name)
    self.tree = tree
\end{minted}

\subsection{Vervangen van de code van een functie door de gegenereerde docstring. v3}
\label{bijlage:vervangen-v3}
\begin{minted}{python}
def _replace_functions(self, node, functions):
    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)) and node.name in functions:
        new_func_def = ast.parse(functions[node.name]).body[0]
        new_func_def.body.extend(node.body)
        parent_node = self._get_parent_node(node)
        index = parent_node.body.index(node)
        parent_node.body.remove(node)
        parent_node.body.insert(index, new_func_def)
        functions.pop(node.name)
    for child_node in ast.iter_child_nodes(node):
        self._replace_functions(child_node, functions)
\end{minted}

\subsection{Genereren van de relaties tussen de verschillende bestanden}
\label{bijlage:generate-file-relations}

\begin{minted}{python}
'''
    You are an AI documentation assistant, and your task is to generate a csv file containing the relations between the files in a Python project.

    For the given project structure and imports:
    The imports are as follows:
    '1_RPS_Game\\CMD_version\\main.py': 'import random', '2_PyPassword_Generator\\CMD_version\\main.py': 'import random', '3_Hangman_Game\\CMD_version\\images.py': '', '3_Hangman_Game\\CMD_version\\main.py': 'import requests\nimport random\nimport os\nfrom images import hangman_logo\nfrom images import stages', '4_Hangman_Game\\CMD_version\\stages.py': '', '4_Hangman_Game\\CMD_version\\images.py': 'import csv\nimport matplotlib', '4_Hangman_Game\\CMD_version\\main.py': 'import random\nimport os\nfrom images import stages\nfrom images import logo'

    The structure of the project is as follows:
    '.': ['LICENSE', 'README.md'], '1_RPS_Game': [], '1_RPS_Game\\CMD_version': ['1_RPS_Game\\CMD_version\\main.py'], '2_PyPassword_Generator': [], '2_PyPassword_Generator\\CMD_version': ['2_PyPassword_Generator\\CMD_version\\main.py'], '3_Hangman_Game': [], '3_Hangman_Game\\CMD_version': ['3_Hangman_Game\\CMD_version\\images.py', '3_Hangman_Game\\CMD_version\\main.py'], '4_Hangman_Game': [], '4_Hangman_Game\\CMD_version': ['4_Hangman_Game\\CMD_version\\stages.py', '4_Hangman_Game\\CMD_version\\images.py', '4_Hangman_Game\\CMD_version\\main.py']

    The expected output of your task is the following:
    ```csv
File_Path,File_Name,Folder_Path,Uses_File
1_RPS_Game\CMD_version\main.py, main.py,1_RPS_Game\CMD_version,[]
2_PyPassword_Generator\CMD_version\main.py,main.py, 2_PyPassword_Generator\CMD_version,[]
3_Hangman_Game\CMD_version\images.py,images.py,3_Hangman_Game\CMD_version,[]
3_Hangman_Game\CMD_version\main.py, main.py,3_Hangman_Game\CMD_version,['3_Hangman_Game.CMD_version.images']
4_Hangman_Game\CMD_version\stages.py,stages.py,4_Hangman_Game\CMD_version,[]
4_Hangman_Game\CMD_version\images.py,images.py,4_Hangman_Game\CMD_version,[]
4_Hangman_Game\CMD_version\main.py,main.py,4_Hangman_Game\CMD_version,['4_Hangman_Game.CMD_version.images';'4_Hangman_Game.CMD_version.stages']
    ```

    The Column "Uses File" should only contain the files where the file imports functions from.
    For example if the imports are:
    ```python
    Import csv
    Import matplotlib
    from images import open_image
    from stages import stage1
    ```
    The Column "Uses File" should contain the file '4_Hangman_Game\\CMD_version\\images.py' and '4_Hangman_Game\\CMD_version\\stages.py'
    Do your task given the following imports and structure of the project:
    
    The imports are as follows:
    {imports}

    And the structure of the project is as follows:
    {structure}

    THE OUTPUT SHOULD BE A SINGLE CSV FILE CONTAINING THE RELATIONS BETWEEN THE FILES IN THE PROJECT.
    '''
\end{minted}

\subsection{Functies voor het samenvatting van een bestand}
\label{bijlage:file-summary-functions}
\begin{minted}{python}
    def document_file(self, file_path, outfolder_path):
        FDG = FileDocumenationGenerator(self.api_key, self.azure_endpoint, file_path, self.folder_path, outfolder_path)
        FDG.generate_file_documentation()
        return FDG

    def generate_file_summaries(self, python_files):
        for file in python_files:
            print("Documenting file: ", file)
            FDG = self.document_file(file, outfolder_path=self.outfolder)
            self.summaries[file] = FDG.get_summary()
            self.imports[file] = FDG.get_imports()
\end{minted}

\subsection{Generatie van een graph van de relaties tussen de bestanden}
\label{bijlage:generate-file-graph}

\begin{minted}{python}
def generate_graph_html(self):
        print("Generating graph html")
        added_edges = set()
        df = pd.read_csv(os.path.join(self.outfolder, 'graph_relations.csv'))
        net = Network(height="750px", width="100%", bgcolor="#222222", font_color="white") 
        net = Network(directed =True)
        net.add_node("root", shape='star', label="")     
        for index, row in df.iterrows():
            path = row['Folder_Path'].split("\\")
            # Add nodes for each folder in the path
            if len(path) > 1:
                for i in range(len(path)-1):
                    path_id = "_".join(path[:i+1])
                    net.add_node(path_id, label=path[i], shape='box')
                    next_path_id = "_".join(path[:i+2])
                    net.add_node("_".join(path[:i+2]), label=path[i+1], shape='box')                        
                    edge = (path_id, next_path_id)
                    if edge not in added_edges:
                        net.add_edge(path_id, next_path_id)
                        added_edges.add(edge)
            elif len(path) == 1:
                    net.add_node(path[0], label=path[0], shape='box')

            # Add node for the file
            file_path = row['File_Path'].split("\\")
            file_id = "_".join(file_path)
            parent_folder_id = "_".join(path)
            net.add_node(file_id, label=file_path[-1])
            edge = (parent_folder_id, file_id)
            if edge not in added_edges:
                net.add_edge(parent_folder_id, file_id)
                added_edges.add(edge)

            # Add edges for the root node
            root_edge = ("root", path[0])
            if root_edge not in added_edges:
                net.add_edge("root", path[0])
                added_edges.add(root_edge)
        
        for index, row in df.iterrows():
            file_id = "_".join(row['File_Path'].split("\\"))
            # Add edges for the uses files
            uses = row['Uses_File'].strip("[]")
            if uses:
                uses = uses.split(";")
                for use_file in uses:
                    use_file_path = use_file.strip("'").split(".")
                    use_file_id = "_".join(use_file_path)+".py"
                    edge = (file_id, use_file_id)
                    if edge not in added_edges:
                        net.add_edge(file_id, use_file_id)
                        added_edges.add(edge)

        path = os.path.join(self.outfolder, 'graph.html')
        net.save_graph(path)
\end{minted}

\section{Zelfgedocumenteerde bestanden}

\subsection{Zelfgedocumenteerd bestand makkelijk niveau}
\label{bijlage:zelfgedocumenteerd-bestand-makkelijk}

\begin{minted}{python}
    def is_prime(n: int) -> bool:
        """
        Check if a number is prime.
        
        Args:
            n (int): The number to check.
        
        Returns:
            bool: True if the number is prime, False otherwise.
        """
        if n in [2, 3]:
            return True
        if (n == 1) or (n % 2 == 0):
            return False
        r = 3
        while r * r <= n:
            if n % r == 0:
                return False
            r += 2
        return True
\end{minted}

\subsection{Zelfgedocumenteerd bestand gemiddeld niveau}
\label{bijlage:zelfgedocumenteerd-bestand}

\begin{minted}{python}
    import os
    import cv2
    import dlib
    from matplotlib import pyplot as plt
    import numpy as np
    import config
    detector = dlib.get_frontal_face_detector()
    
    def crop_faces(plot_images: bool=False, max_images_to_plot: int=5):
        """
        Crop faces from images in the original images directory and save them in the cropped images directory.
    
        Args: 
            plot_images (bool): Whether to plot the cropped images. Defaults to False.
            max_images_to_plot (int): Maximum number of images to plot. Defaults to 5.
        
        Returns:
            List[np.array]: List of good cropped images.
        """
        bad_crop_count = 0
        if not os.path.exists(config.CROPPED_IMGS_DIR):
            os.makedirs(config.CROPPED_IMGS_DIR)
        print('Cropping faces and saving to %s' % config.CROPPED_IMGS_DIR)
        good_cropped_images = []
        good_cropped_img_file_names = []
        detected_cropped_images = []
        original_images_detected = []
        for file_name in sorted(os.listdir(config.ORIGINAL_IMGS_DIR)):
            np_img = cv2.imread(os.path.join(config.ORIGINAL_IMGS_DIR, file_name))
            detected = detector(np_img, 1)
            img_h, img_w, _ = np.shape(np_img)
            original_images_detected.append(np_img)
            if len(detected) != 1:
                bad_crop_count += 1
                continue
            d = detected[0]
            x1, y1, x2, y2, w, h = (d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height())
            xw1 = int(x1 - config.MARGIN * w)
            yw1 = int(y1 - config.MARGIN * h)
            xw2 = int(x2 + config.MARGIN * w)
            yw2 = int(y2 + config.MARGIN * h)
            cropped_img = crop_image(np_img, xw1, yw1, xw2, yw2)
            norm_file_path = '%s/%s' % (config.CROPPED_IMGS_DIR, file_name)
            cv2.imwrite(norm_file_path, cropped_img)
            good_cropped_img_file_names.append(file_name)
        with open(config.ORIGINAL_IMGS_INFO_FILE, 'r') as f:
            column_headers = f.read().splitlines()[0]
            all_imgs_info = f.read().splitlines()[1:]
        cropped_imgs_info = [l for l in all_imgs_info if l.split(',')[-1] in good_cropped_img_file_names]
        with open(config.CROPPED_IMGS_INFO_FILE, 'w') as f:
            f.write('%s\n' % column_headers)
            for l in cropped_imgs_info:
                f.write('%s\n' % l)
        print('Cropped %d images and saved in %s - info in %s' % (len(original_images_detected), config.CROPPED_IMGS_DIR, config.CROPPED_IMGS_INFO_FILE))
        print('Error detecting face in %d images - info in Data/unnormalized.txt' % bad_crop_count)
        if plot_images:
            print('Plotting images...')
            img_index = 0
            plot_index = 1
            plot_n_cols = 3
            plot_n_rows = len(original_images_detected) if len(original_images_detected) < max_images_to_plot else max_images_to_plot
            for row in range(plot_n_rows):
                plt.subplot(plot_n_rows, plot_n_cols, plot_index)
                plt.imshow(original_images_detected[img_index].astype('uint8'))
                plot_index += 1
                plt.subplot(plot_n_rows, plot_n_cols, plot_index)
                plt.imshow(detected_cropped_images[img_index])
                plot_index += 1
                plt.subplot(plot_n_rows, plot_n_cols, plot_index)
                plt.imshow(good_cropped_images[img_index])
                plot_index += 1
                img_index += 1
        plt.show()
        return good_cropped_images
    
    def crop_image(img, x1, y1, x2, y2):
        """
        Crop an image to the bounding box defined by the coordinates (x1, y1, x2, y2).
    
        Args:
            img (np.ndarray): Input image.
            x1 (int): x-coordinate of the top-left corner of the bounding box.
            y1 (int): y-coordinate of the top-left corner of the bounding box.
            x2 (int): x-coordinate of the bottom-right corner of the bounding box.
            y2 (int): y-coordinate of the bottom-right corner of the bounding box.
        
        Returns:
            np.ndarray: Cropped image.    
        """
        if x1 < 0 or y1 < 0 or x2 > img.shape[1] or (y2 > img.shape[0]):
            img, x1, x2, y1, y2 = pad_img_to_fit_bbox(img, x1, x2, y1, y2)
        return img[y1:y2, x1:x2, :]
    
    def pad_img_to_fit_bbox(img, x1, x2, y1, y2):
        """
        Pad an image to fit a bounding box.
    
        Args:
            img (np.array): Input image.
            x1 (int): x-coordinate of the top-left corner of the bounding box.
            x2 (int): x-coordinate of the bottom-right corner of the bounding box.
            y1 (int): y-coordinate of the top-left corner of the bounding box.
            y2 (int): y-coordinate of the bottom-right corner of the bounding box.
        
        Returns:
            Tuple[np.array, int, int, int, int]: Padded image and updated coordinates.
        """
        img = cv2.copyMakeBorder(img, -min(0, y1), max(y2 - img.shape[0], 0), -min(0, x1), max(x2 - img.shape[1], 0), cv2.BORDER_REPLICATE)
        y2 += -min(0, y1)
        y1 += -min(0, y1)
        x2 += -min(0, x1)
        x1 += -min(0, x1)
        return (img, x1, x2, y1, y2)
    
    if __name__ == '__main__':
        crop_faces()
    
    """
    Summary of file: crop_images.py
    
    This file contains the implementation of functions to crop and pad images.
    
    Functions:
        crop_faces: Crop faces from an image based on the given bounding boxes.
        crop_image: Crop an image to the bounding box defined by the coordinates (x1, y1, x2, y2).
        pad_img_to_fit_bbox: Pad an image to fit a bounding box.
    """
\end{minted}

\subsection{Zelfgedocumenteerd bestand moeilijk niveau}
\label{bijlage:zelfgedocumenteerd-bestand-2}

\begin{minted}{python}
import csv

class CsvReader:
    """
    A class to read csv files

    Methods:
        readCsv(filename): Reads a csv file and returns the data in a list of lists

    """
    def readCsv(self, filename):
        """
        Reads a csv file and returns the data in a list of lists
        
        Args: 
            filename (str): Name of the file to read
        
        Returns:
            list[list[str]]: List of lists containing the data from the csv file
        """
        self.rowData = []
        self.lineCount = 0
        with open(filename) as csvFile:
            self.csvReader = csv.reader(csvFile, delimiter=',')
            for row in self.csvReader:
                if self.lineCount == 0 or self.lineCount == 1:
                    self.lineCount += 1
                else:
                    self.rowData.append(row)
                    self.lineCount += 1
        return self.rowData
    
"""
Summary of file CsvReader.py:

This file contains a class CsvReader that reads csv files. 

Classes:
    CsvReader: A class to read csv files

    Methods:
        readCsv: Reads a csv file and returns the data in a list of lists
"""
\end{minted}

\section{Python bestanden geclassifierd op moeilijkheidsgraad}
\label{bijlage:bestanden-moeilijkheidsgraad}

\subsection{Makkelijk}
\label{bijlage:makkelijk}

\begin{minted}{python}
def is_prime(n):
    if n in [2, 3]:
        return True
    if (n == 1) or (n % 2 == 0):
        return False
    r = 3
    while r * r <= n:
        if n % r == 0:
            return False
        r += 2
    return True
\end{minted}

\subsection{Gemiddeld}
\label{bijlage:gemiddeld}

\begin{minted}{python}
import os
import cv2
import dlib
from matplotlib import pyplot as plt
import numpy as np
import config

detector = dlib.get_frontal_face_detector()


def crop_faces(plot_images=False, max_images_to_plot=5):
    bad_crop_count = 0
    if not os.path.exists(config.CROPPED_IMGS_DIR):
        os.makedirs(config.CROPPED_IMGS_DIR)
    print('Cropping faces and saving to %s' % config.CROPPED_IMGS_DIR)
    good_cropped_images = []
    good_cropped_img_file_names = []
    detected_cropped_images = []
    original_images_detected = []
    for file_name in sorted(os.listdir(config.ORIGINAL_IMGS_DIR)):
        np_img = cv2.imread(os.path.join(config.ORIGINAL_IMGS_DIR,file_name))
        detected = detector(np_img, 1)
        img_h, img_w, _ = np.shape(np_img)
        original_images_detected.append(np_img)

        if len(detected) != 1:
            bad_crop_count += 1
            continue

        d = detected[0]
        x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()
        xw1 = int(x1 - config.MARGIN * w)
        yw1 = int(y1 - config.MARGIN * h)
        xw2 = int(x2 + config.MARGIN * w)
        yw2 = int(y2 + config.MARGIN * h)
        cropped_img = crop_image(np_img, xw1, yw1, xw2, yw2)
        norm_file_path = '%s/%s' % (config.CROPPED_IMGS_DIR, file_name)
        cv2.imwrite(norm_file_path, cropped_img)

        good_cropped_img_file_names.append(file_name)

    # save info of good cropped images
    with open(config.ORIGINAL_IMGS_INFO_FILE, 'r') as f:
        column_headers = f.read().splitlines()[0]
        all_imgs_info = f.read().splitlines()[1:]
    cropped_imgs_info = [l for l in all_imgs_info if l.split(',')[-1] in good_cropped_img_file_names]

    with open(config.CROPPED_IMGS_INFO_FILE, 'w') as f:
        f.write('%s\n' % column_headers)
        for l in cropped_imgs_info:
            f.write('%s\n' % l)

    print('Cropped %d images and saved in %s - info in %s' % (len(original_images_detected), config.CROPPED_IMGS_DIR, config.CROPPED_IMGS_INFO_FILE))
    print('Error detecting face in %d images - info in Data/unnormalized.txt' % bad_crop_count)

    if plot_images:
        print('Plotting images...')
        img_index = 0
        plot_index = 1
        plot_n_cols = 3
        plot_n_rows = len(original_images_detected) if len(original_images_detected) < max_images_to_plot else max_images_to_plot
        for row in range(plot_n_rows):
            plt.subplot(plot_n_rows,plot_n_cols,plot_index)
            plt.imshow(original_images_detected[img_index].astype('uint8'))
            plot_index += 1

            plt.subplot(plot_n_rows,plot_n_cols,plot_index)
            plt.imshow(detected_cropped_images[img_index])
            plot_index += 1

            plt.subplot(plot_n_rows,plot_n_cols,plot_index)
            plt.imshow(good_cropped_images[img_index])
            plot_index += 1

            img_index += 1
    plt.show()
    return good_cropped_images



# image cropping method taken from:
# https://stackoverflow.com/questions/15589517/how-to-crop-an-image-in-opencv-using-python
def crop_image(img, x1, y1, x2, y2):
    if x1 < 0 or y1 < 0 or x2 > img.shape[1] or y2 > img.shape[0]:
        img, x1, x2, y1, y2 = pad_img_to_fit_bbox(img, x1, x2, y1, y2)
    return img[y1:y2, x1:x2, :]

def pad_img_to_fit_bbox(img, x1, x2, y1, y2):
    img = cv2.copyMakeBorder(img, - min(0, y1), max(y2 - img.shape[0], 0),
                             -min(0, x1), max(x2 - img.shape[1], 0), cv2.BORDER_REPLICATE)
    y2 += -min(0, y1)
    y1 += -min(0, y1)
    x2 += -min(0, x1)
    x1 += -min(0, x1)
    return img, x1, x2, y1, y2

if __name__ == '__main__':
    crop_faces()
\end{minted}

\subsection{Moeilijk}
\label{bijlage:moeilijk}

\begin{minted}{python}
import csv

class CsvReader:
    def readCsv(self, filename):
        self.rowData = []
        self.lineCount = 0
        with open(filename) as csvFile:
            self.csvReader = csv.reader(csvFile, delimiter=',')
            for row in self.csvReader:
                if self.lineCount == 0 or self.lineCount == 1:
                    self.lineCount += 1
                else:
                    self.rowData.append(row)
                    self.lineCount += 1
        return self.rowData
\end{minted}

\subsection{Extreem moeilijk}
\label{bijlage:extreem-moeilijk}

\begin{minted}{python}
import inspect
import os
import sys
import time
from dataclasses import dataclass

import tiktoken
from openai import APIConnectionError, OpenAI

from repo_agent.doc_meta_info import DocItem
from repo_agent.log import logger
from repo_agent.prompt import SYS_PROMPT, USR_PROMPT
from repo_agent.settings import max_input_tokens_map, setting


def get_import_statements():
    source_lines = inspect.getsourcelines(sys.modules[__name__])[0]
    import_lines = [
        line
        for line in source_lines
        if line.strip().startswith("import") or line.strip().startswith("from")
    ]
    return import_lines

@dataclass
class ResponseMessage:
    content: str


class ChatEngine:
    """
    ChatEngine is used to generate the doc of functions or classes.
    """

    def __init__(self, project_manager):
        self.project_manager = project_manager

    def num_tokens_from_string(self, string: str, encoding_name="cl100k_base") -> int:
        """Returns the number of tokens in a text string."""
        encoding = tiktoken.get_encoding(encoding_name)
        num_tokens = len(encoding.encode(string))
        return num_tokens

    def reduce_input_length(self, shorten_attempt, prompt_data):
        """
        Reduces the length of the input prompts by modifying the sys_prompt contents.
        """

        logger.info(
            f"Attempt {shorten_attempt + 1} / 2 to reduce the length of the messages."
        )
        if shorten_attempt == 0:
            # First attempt, remove project_structure and project_structure_prefix
            prompt_data.project_structure = ""
            prompt_data.project_structure_prefix = ""
        elif shorten_attempt == 1:
            # Second attempt, futher remove caller and callee (reference) information
            prompt_data.project_structure = ""
            prompt_data.project_structure_prefix = ""

            prompt_data.referenced = False
            prompt_data.referencer_content = ""
            prompt_data.reference_letter = ""
            prompt_data.combine_ref_situation = ""

        # Update sys_prompt
        sys_prompt = SYS_PROMPT.format(**prompt_data)

        return sys_prompt

    def generate_response(self, model, sys_prompt, usr_prompt, max_tokens):
        client = OpenAI(
            api_key=setting.chat_completion.openai_api_key.get_secret_value(),
            base_url=str(setting.chat_completion.base_url),
            timeout=setting.chat_completion.request_timeout,
        )

        messages = [
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": usr_prompt},
        ]

        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=setting.chat_completion.temperature,
            max_tokens=max_tokens,
        )

        response_message = response.choices[0].message

        return response_message

    def attempt_generate_response(
        self, model, sys_prompt, usr_prompt, max_tokens, max_attempts=5
    ):
        attempt = 0
        while attempt < max_attempts:
            try:
                response_message = self.generate_response(
                    model, sys_prompt, usr_prompt, max_tokens
                )

                if response_message is None:
                    attempt += 1
                    continue
                return response_message

            except APIConnectionError as e:
                logger.error(
                    f"Connection error: {e}. Attempt {attempt + 1} of {max_attempts}"
                )
                # Retry after 7 seconds
                time.sleep(7)
                attempt += 1
                if attempt == max_attempts:
                    raise
                else:
                    continue  # Try to request again

            except Exception as e:
                logger.error(
                    f"An unknown error occurred: {e}. \nAttempt {attempt + 1} of {max_attempts}"
                )
                # Retry after 10 seconds
                time.sleep(10)
                attempt += 1
                if attempt == max_attempts:
                    response_message = ResponseMessage(
                        "An unknown error occurred while generating this documentation after many tries."
                    )
                    return response_message

    def generate_doc(self, doc_item: DocItem, file_handler):
        code_info = doc_item.content
        referenced = len(doc_item.who_reference_me) > 0

        code_type = code_info["type"]
        code_name = code_info["name"]
        code_content = code_info["code_content"]
        have_return = code_info["have_return"]
        who_reference_me = doc_item.who_reference_me_name_list
        reference_who = doc_item.reference_who_name_list
        file_path = doc_item.get_full_name()
        doc_item_path = os.path.join(file_path, code_name)

        project_structure = self.project_manager.build_path_tree(
            who_reference_me, reference_who, doc_item_path
        )

        # project_manager = ProjectManager(repo_path=file_handler.repo_path, project_hierarchy=file_handler.project_hierarchy)
        # project_structure = project_manager.get_project_structure()
        # file_path = os.path.join(file_handler.repo_path, file_handler.file_path)
        # code_from_referencer = get_code_from_json(project_manager.project_hierarchy, referencer) #
        # referenced = True if len(code_from_referencer) > 0 else False
        # referencer_content = '\n'.join([f'File_Path:{file_path}\n' + '\n'.join([f'Corresponding code as follows:\n{code}\n[End of this part of code]' for code in codes]) + f'\n[End of {file_path}]' for file_path, codes in code_from_referencer.items()])

        def get_referenced_prompt(doc_item: DocItem) -> str:
            if len(doc_item.reference_who) == 0:
                return ""
            prompt = [
                """As you can see, the code calls the following objects, their code and docs are as following:"""
            ]
            for k, reference_item in enumerate(doc_item.reference_who):
                instance_prompt = (
                    f"""obj: {reference_item.get_full_name()}\nDocument: \n{reference_item.md_content[-1] if len(reference_item.md_content) > 0 else 'None'}\nRaw code:```\n{reference_item.content['code_content'] if 'code_content' in reference_item.content.keys() else ''}\n```"""
                    + "=" * 10
                )
                prompt.append(instance_prompt)
            return "\n".join(prompt)

        def get_referencer_prompt(doc_item: DocItem) -> str:
            if len(doc_item.who_reference_me) == 0:
                return ""
            prompt = [
                """Also, the code has been called by the following objects, their code and docs are as following:"""
            ]
            for k, referencer_item in enumerate(doc_item.who_reference_me):
                instance_prompt = (
                    f"""obj: {referencer_item.get_full_name()}\nDocument: \n{referencer_item.md_content[-1] if len(referencer_item.md_content) > 0 else 'None'}\nRaw code:```\n{referencer_item.content['code_content'] if 'code_content' in referencer_item.content.keys() else 'None'}\n```"""
                    + "=" * 10
                )
                prompt.append(instance_prompt)
            return "\n".join(prompt)

        def get_relationship_description(referencer_content, reference_letter):
            if referencer_content and reference_letter:
                return "And please include the reference relationship with its callers and callees in the project from a functional perspective"
            elif referencer_content:
                return "And please include the relationship with its callers in the project from a functional perspective."
            elif reference_letter:
                return "And please include the relationship with its callees in the project from a functional perspective."
            else:
                return ""

        max_tokens = setting.project.max_document_tokens

        code_type_tell = "Class" if code_type == "ClassDef" else "Function"
        parameters_or_attribute = (
            "attributes" if code_type == "ClassDef" else "parameters"
        )
        have_return_tell = (
            "**Output Example**: Mock up a possible appearance of the code's return value."
            if have_return
            else ""
        )
        # reference_letter = "This object is called in the following files, the file paths and corresponding calling parts of the code are as follows:" if referenced else ""
        combine_ref_situation = (
            "and combine it with its calling situation in the project,"
            if referenced
            else ""
        )

        referencer_content = get_referencer_prompt(doc_item)
        reference_letter = get_referenced_prompt(doc_item)
        has_relationship = get_relationship_description(
            referencer_content, reference_letter
        )

        project_structure_prefix = ", and the related hierarchical structure of this project is as follows (The current object is marked with an *):"

        prompt_data = {
            "combine_ref_situation": combine_ref_situation,
            "file_path": file_path,
            "project_structure_prefix": project_structure_prefix,
            "project_structure": project_structure,
            "code_type_tell": code_type_tell,
            "code_name": code_name,
            "code_content": code_content,
            "have_return_tell": have_return_tell,
            "has_relationship": has_relationship,
            "reference_letter": reference_letter,
            "referencer_content": referencer_content,
            "parameters_or_attribute": parameters_or_attribute,
            "language": setting.project.language,
        }

        sys_prompt = SYS_PROMPT.format(**prompt_data)

        usr_prompt = USR_PROMPT.format(language=setting.project.language)

        model = setting.chat_completion.model
        max_input_length = max_input_tokens_map.get(model, 4096) - max_tokens

        total_tokens = self.num_tokens_from_string(
            sys_prompt
        ) + self.num_tokens_from_string(usr_prompt)

        if total_tokens >= max_input_length:
            larger_models = {
                k: v
                for k, v in max_input_tokens_map.items()
                if (v - max_tokens) > total_tokens
            }  
            for model_name, max_input_length in larger_models.items():
                if max_input_length - max_tokens > total_tokens:
                    try:
                        # Attempt to make a request with the larger model
                        logger.info(
                            f"Trying model {model_name} for large-context processing."
                        )
                        response_message = self.attempt_generate_response(
                            model_name, sys_prompt, usr_prompt, max_tokens
                        )  
                        return response_message
                    except Exception as e:
                        continue  # Try the next model
            # If no larger models succeed, fallback to original model
            for shorten_attempt in range(2):
                shorten_success = False
                sys_prompt = self.reduce_input_length(shorten_attempt, prompt_data)
                total_tokens = self.num_tokens_from_string(
                    sys_prompt
                ) + self.num_tokens_from_string(usr_prompt)
                if total_tokens < max_input_length:
                    shorten_success = True
                    response_message = self.attempt_generate_response(
                        model, sys_prompt, usr_prompt, max_tokens
                    )

            if not shorten_success:
                response_message = ResponseMessage(
                    "Tried to generate the document, but the code is too long to process."
                )
                return response_message

        else: 
            response_message = self.attempt_generate_response(
                model, sys_prompt, usr_prompt, max_tokens
            )

        return response_message
\end{minted}


\section{Uitkomst documentatie van de Python bestanden}

\subsection{Uitkomst documentatie van gemiddeld bestand}
\label{bijlage:uitkomst-gemiddeld}

\begin{minted}{python}
import os
import cv2
import dlib
from matplotlib import pyplot as plt
import numpy as np
import config
detector = dlib.get_frontal_face_detector()

def crop_faces(plot_images=False, max_images_to_plot=5):

    def crop_faces(plot_images: bool=False, max_images_to_plot: int=5) -> List[np.ndarray]:
        """
        Crop faces from original images and save the cropped images.

        Args:
            plot_images (bool, optional): Whether to plot the cropped images. Defaults to False.
            max_images_to_plot (int, optional): Maximum number of images to plot. Defaults to 5.
        
        Returns:
            List[np.ndarray]: List of good cropped images.
        """
        bad_crop_count = 0
        if not os.path.exists(config.CROPPED_IMGS_DIR):
            os.makedirs(config.CROPPED_IMGS_DIR)
        print('Cropping faces and saving to %s' % config.CROPPED_IMGS_DIR)
        good_cropped_images = []
        good_cropped_img_file_names = []
        detected_cropped_images = []
        original_images_detected = []
        for file_name in sorted(os.listdir(config.ORIGINAL_IMGS_DIR)):
            np_img = cv2.imread(os.path.join(config.ORIGINAL_IMGS_DIR, file_name))
            detected = detector(np_img, 1)
            img_h, img_w, _ = np.shape(np_img)
            original_images_detected.append(np_img)
            if len(detected) != 1:
                bad_crop_count += 1
                continue
            d = detected[0]
            x1, y1, x2, y2, w, h = (d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height())
            xw1 = int(x1 - config.MARGIN * w)
            yw1 = int(y1 - config.MARGIN * h)
            xw2 = int(x2 + config.MARGIN * w)
            yw2 = int(y2 + config.MARGIN * h)
            cropped_img = crop_image(np_img, xw1, yw1, xw2, yw2)
            norm_file_path = '%s/%s' % (config.CROPPED_IMGS_DIR, file_name)
            cv2.imwrite(norm_file_path, cropped_img)
            good_cropped_img_file_names.append(file_name)
        with open(config.ORIGINAL_IMGS_INFO_FILE, 'r') as f:
            column_headers = f.read().splitlines()[0]
            all_imgs_info = f.read().splitlines()[1:]
        cropped_imgs_info = [l for l in all_imgs_info if l.split(',')[-1] in good_cropped_img_file_names]
        with open(config.CROPPED_IMGS_INFO_FILE, 'w') as f:
            f.write('%s\n' % column_headers)
            for l in cropped_imgs_info:
                f.write('%s\n' % l)
        print('Cropped %d images and saved in %s - info in %s' % (len(original_images_detected), config.CROPPED_IMGS_DIR, config.CROPPED_IMGS_INFO_FILE))
        print('Error detecting face in %d images - info in Data/unnormalized.txt' % bad_crop_count)
        if plot_images:
            print('Plotting images...')
            img_index = 0
            plot_index = 1
            plot_n_cols = 3
            plot_n_rows = len(original_images_detected) if len(original_images_detected) < max_images_to_plot else max_images_to_plot
            for row in range(plot_n_rows):
                plt.subplot(plot_n_rows, plot_n_cols, plot_index)
                plt.imshow(original_images_detected[img_index].astype('uint8'))
                plot_index += 1
                plt.subplot(plot_n_rows, plot_n_cols, plot_index)
                plt.imshow(detected_cropped_images[img_index])
                plot_index += 1
                plt.subplot(plot_n_rows, plot_n_cols, plot_index)
                plt.imshow(good_cropped_images[img_index])
                plot_index += 1
                img_index += 1
        plt.show()
        return good_cropped_images

def crop_image(img, x1, y1, x2, y2):

    def crop_image(img: ndarray, x1: int, y1: int, x2: int, y2: int) -> ndarray:
        """
        Crop the input image to the specified dimensions.

        Args:
            img (ndarray): The input image.
            x1 (int): The starting x-coordinate for cropping.
            y1 (int): The starting y-coordinate for cropping.
            x2 (int): The ending x-coordinate for cropping.
            y2 (int): The ending y-coordinate for cropping.

        Returns:
            ndarray: The cropped image.
        """
        if x1 < 0 or y1 < 0 or x2 > img.shape[1] or (y2 > img.shape[0]):
            img, x1, x2, y1, y2 = pad_img_to_fit_bbox(img, x1, x2, y1, y2)
        return img[y1:y2, x1:x2, :]

def pad_img_to_fit_bbox(img, x1, x2, y1, y2):

    def pad_img_to_fit_bbox(img: numpy.ndarray, x1: int, x2: int, y1: int, y2: int) -> tuple:
        """
    Pads an image to fit a bounding box.

    Args:
        img (numpy.ndarray): The image to pad.
        x1 (int): Left boundary of the bounding box.
        x2 (int): Right boundary of the bounding box.
        y1 (int): Top boundary of the bounding box.
        y2 (int): Bottom boundary of the bounding box.

    Returns:
        tuple: A tuple containing the padded image and the updated bounding box coordinates (x1, x2, y1, y2).
    """
        img = cv2.copyMakeBorder(img, -min(0, y1), max(y2 - img.shape[0], 0), -min(0, x1), max(x2 - img.shape[1], 0), cv2.BORDER_REPLICATE)
        y2 += -min(0, y1)
        y1 += -min(0, y1)
        x2 += -min(0, x1)
        x1 += -min(0, x1)
        return (img, x1, x2, y1, y2)
if __name__ == '__main__':
    crop_faces()
\end{minted}

\section{Evaluatie bestand documentatie}
\label{bijlage:evaluatie-bestand-documentatie}

\subsection{Uitkomst van bestand documentatie door eigen tool}
\begin{minted}{python}
import os
import cv2
import dlib
from matplotlib import pyplot as plt
import numpy as np
import config
detector = dlib.get_frontal_face_detector()

def crop_faces(plot_images: bool=False, max_images_to_plot: int=5) -> List[np.ndarray]:
    """
    Crop faces from the original images and save the cropped images.

    Args:
        plot_images (bool, optional): Whether to plot the images. Defaults to False.
        max_images_to_plot (int, optional): Maximum number of images to plot. Defaults to 5.

    Returns:
        List[np.ndarray]: List of good cropped images.
    """
    bad_crop_count = 0
    if not os.path.exists(config.CROPPED_IMGS_DIR):
        os.makedirs(config.CROPPED_IMGS_DIR)
    print('Cropping faces and saving to %s' % config.CROPPED_IMGS_DIR)
    good_cropped_images = []
    good_cropped_img_file_names = []
    detected_cropped_images = []
    original_images_detected = []
    for file_name in sorted(os.listdir(config.ORIGINAL_IMGS_DIR)):
        np_img = cv2.imread(os.path.join(config.ORIGINAL_IMGS_DIR, file_name))
        detected = detector(np_img, 1)
        img_h, img_w, _ = np.shape(np_img)
        original_images_detected.append(np_img)
        if len(detected) != 1:
            bad_crop_count += 1
            continue
        d = detected[0]
        x1, y1, x2, y2, w, h = (d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height())
        xw1 = int(x1 - config.MARGIN * w)
        yw1 = int(y1 - config.MARGIN * h)
        xw2 = int(x2 + config.MARGIN * w)
        yw2 = int(y2 + config.MARGIN * h)
        cropped_img = crop_image(np_img, xw1, yw1, xw2, yw2)
        norm_file_path = '%s/%s' % (config.CROPPED_IMGS_DIR, file_name)
        cv2.imwrite(norm_file_path, cropped_img)
        good_cropped_img_file_names.append(file_name)
    with open(config.ORIGINAL_IMGS_INFO_FILE, 'r') as f:
        column_headers = f.read().splitlines()[0]
        all_imgs_info = f.read().splitlines()[1:]
    cropped_imgs_info = [l for l in all_imgs_info if l.split(',')[-1] in good_cropped_img_file_names]
    with open(config.CROPPED_IMGS_INFO_FILE, 'w') as f:
        f.write('%s\n' % column_headers)
        for l in cropped_imgs_info:
            f.write('%s\n' % l)
    print('Cropped %d images and saved in %s - info in %s' % (len(original_images_detected), config.CROPPED_IMGS_DIR, config.CROPPED_IMGS_INFO_FILE))
    print('Error detecting face in %d images - info in Data/unnormalized.txt' % bad_crop_count)
    if plot_images:
        print('Plotting images...')
        img_index = 0
        plot_index = 1
        plot_n_cols = 3
        plot_n_rows = len(original_images_detected) if len(original_images_detected) < max_images_to_plot else max_images_to_plot
        for row in range(plot_n_rows):
            plt.subplot(plot_n_rows, plot_n_cols, plot_index)
            plt.imshow(original_images_detected[img_index].astype('uint8'))
            plot_index += 1
            plt.subplot(plot_n_rows, plot_n_cols, plot_index)
            plt.imshow(detected_cropped_images[img_index])
            plot_index += 1
            plt.subplot(plot_n_rows, plot_n_cols, plot_index)
            plt.imshow(good_cropped_images[img_index])
            plot_index += 1
            img_index += 1
    plt.show()
    return good_cropped_images

def crop_image(img: np.ndarray, x1: int, y1: int, x2: int, y2: int) -> np.ndarray:
    """
    Crop a region from the input image based on the specified coordinates.

    Args:
        img (np.ndarray): The input image.
        x1 (int): The starting x-coordinate of the region to be cropped.
        y1 (int): The starting y-coordinate of the region to be cropped.
        x2 (int): The ending x-coordinate of the region to be cropped.
        y2 (int): The ending y-coordinate of the region to be cropped.

    Returns:
        np.ndarray: The cropped region of the image.
    """
    if x1 < 0 or y1 < 0 or x2 > img.shape[1] or (y2 > img.shape[0]):
        img, x1, x2, y1, y2 = pad_img_to_fit_bbox(img, x1, x2, y1, y2)
    return img[y1:y2, x1:x2, :]

def pad_img_to_fit_bbox(img: np.array, x1: int, x2: int, y1: int, y2: int) -> Tuple[np.array, int, int, int, int]:
    """
    Pad the image to fit the specified bounding box coordinates.

    Args:
        img (np.array): The input image.
        x1 (int): The x-coordinate of the left side of the bounding box.
        x2 (int): The x-coordinate of the right side of the bounding box.
        y1 (int): The y-coordinate of the top side of the bounding box.
        y2 (int): The y-coordinate of the bottom side of the bounding box.

    Returns:
        Tuple[np.array, int, int, int, int]: The padded image and updated coordinates of the bounding box.
    """
    img = cv2.copyMakeBorder(img, -min(0, y1), max(y2 - img.shape[0], 0), -min(0, x1), max(x2 - img.shape[1], 0), cv2.BORDER_REPLICATE)
    y2 += -min(0, y1)
    y1 += -min(0, y1)
    x2 += -min(0, x1)
    x1 += -min(0, x1)
    return (img, x1, x2, y1, y2)
if __name__ == '__main__':
    crop_faces()


"""
Summary of file: crop_images.py

This file contains the implementation of functions to crop and pad images.

Functions:
    crop_faces: Crop faces from an image and return a list of cropped faces.
    crop_image: Crop a specified region from an image.
    pad_img_to_fit_bbox: Pad an image to fit a specified bounding box.
"""
\end{minted}

\subsection{Zelfgedocumenteerd bestand gemiddeld niveau}
\label{bijlage:zelfgedocumenteerd-bestand-gemiddeld}

\begin{minted}{python}
import os
import cv2
import dlib
from matplotlib import pyplot as plt
import numpy as np
import config
detector = dlib.get_frontal_face_detector()

def crop_faces(plot_images: bool=False, max_images_to_plot: int=5):
    """
    Crop faces from images in the original images directory and save them in the cropped images directory.

    Args: 
        plot_images (bool): Whether to plot the cropped images. Defaults to False.
        max_images_to_plot (int): Maximum number of images to plot. Defaults to 5.
    
    Returns:
        List[np.array]: List of good cropped images.
    """
    bad_crop_count = 0
    if not os.path.exists(config.CROPPED_IMGS_DIR):
        os.makedirs(config.CROPPED_IMGS_DIR)
    print('Cropping faces and saving to %s' % config.CROPPED_IMGS_DIR)
    good_cropped_images = []
    good_cropped_img_file_names = []
    detected_cropped_images = []
    original_images_detected = []
    for file_name in sorted(os.listdir(config.ORIGINAL_IMGS_DIR)):
        np_img = cv2.imread(os.path.join(config.ORIGINAL_IMGS_DIR, file_name))
        detected = detector(np_img, 1)
        img_h, img_w, _ = np.shape(np_img)
        original_images_detected.append(np_img)
        if len(detected) != 1:
            bad_crop_count += 1
            continue
        d = detected[0]
        x1, y1, x2, y2, w, h = (d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height())
        xw1 = int(x1 - config.MARGIN * w)
        yw1 = int(y1 - config.MARGIN * h)
        xw2 = int(x2 + config.MARGIN * w)
        yw2 = int(y2 + config.MARGIN * h)
        cropped_img = crop_image(np_img, xw1, yw1, xw2, yw2)
        norm_file_path = '%s/%s' % (config.CROPPED_IMGS_DIR, file_name)
        cv2.imwrite(norm_file_path, cropped_img)
        good_cropped_img_file_names.append(file_name)
    with open(config.ORIGINAL_IMGS_INFO_FILE, 'r') as f:
        column_headers = f.read().splitlines()[0]
        all_imgs_info = f.read().splitlines()[1:]
    cropped_imgs_info = [l for l in all_imgs_info if l.split(',')[-1] in good_cropped_img_file_names]
    with open(config.CROPPED_IMGS_INFO_FILE, 'w') as f:
        f.write('%s\n' % column_headers)
        for l in cropped_imgs_info:
            f.write('%s\n' % l)
    print('Cropped %d images and saved in %s - info in %s' % (len(original_images_detected), config.CROPPED_IMGS_DIR, config.CROPPED_IMGS_INFO_FILE))
    print('Error detecting face in %d images - info in Data/unnormalized.txt' % bad_crop_count)
    if plot_images:
        print('Plotting images...')
        img_index = 0
        plot_index = 1
        plot_n_cols = 3
        plot_n_rows = len(original_images_detected) if len(original_images_detected) < max_images_to_plot else max_images_to_plot
        for row in range(plot_n_rows):
            plt.subplot(plot_n_rows, plot_n_cols, plot_index)
            plt.imshow(original_images_detected[img_index].astype('uint8'))
            plot_index += 1
            plt.subplot(plot_n_rows, plot_n_cols, plot_index)
            plt.imshow(detected_cropped_images[img_index])
            plot_index += 1
            plt.subplot(plot_n_rows, plot_n_cols, plot_index)
            plt.imshow(good_cropped_images[img_index])
            plot_index += 1
            img_index += 1
    plt.show()
    return good_cropped_images

def crop_image(img, x1, y1, x2, y2):
    """
    Crop an image to the bounding box defined by the coordinates (x1, y1, x2, y2).

    Args:
        img (np.ndarray): Input image.
        x1 (int): x-coordinate of the top-left corner of the bounding box.
        y1 (int): y-coordinate of the top-left corner of the bounding box.
        x2 (int): x-coordinate of the bottom-right corner of the bounding box.
        y2 (int): y-coordinate of the bottom-right corner of the bounding box.
    
    Returns:
        np.ndarray: Cropped image.    
    """
    if x1 < 0 or y1 < 0 or x2 > img.shape[1] or (y2 > img.shape[0]):
        img, x1, x2, y1, y2 = pad_img_to_fit_bbox(img, x1, x2, y1, y2)
    return img[y1:y2, x1:x2, :]

def pad_img_to_fit_bbox(img, x1, x2, y1, y2):
    """
    Pad an image to fit a bounding box.

    Args:
        img (np.array): Input image.
        x1 (int): x-coordinate of the top-left corner of the bounding box.
        x2 (int): x-coordinate of the bottom-right corner of the bounding box.
        y1 (int): y-coordinate of the top-left corner of the bounding box.
        y2 (int): y-coordinate of the bottom-right corner of the bounding box.
    
    Returns:
        Tuple[np.array, int, int, int, int]: Padded image and updated coordinates.
    """
    img = cv2.copyMakeBorder(img, -min(0, y1), max(y2 - img.shape[0], 0), -min(0, x1), max(x2 - img.shape[1], 0), cv2.BORDER_REPLICATE)
    y2 += -min(0, y1)
    y1 += -min(0, y1)
    x2 += -min(0, x1)
    x1 += -min(0, x1)
    return (img, x1, x2, y1, y2)

if __name__ == '__main__':
    crop_faces()

"""
Summary of file: crop_images.py

This file contains the implementation of functions to crop and pad images.

Functions:
    crop_faces: Crop faces from an image based on the given bounding boxes.
    crop_image: Crop an image to the bounding box defined by the coordinates (x1, y1, x2, y2).
    pad_img_to_fit_bbox: Pad an image to fit a bounding box.
"""
\end{minted}


